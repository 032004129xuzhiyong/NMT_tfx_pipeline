{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fe1286-47a5-4d12-b3cb-1fde0d92bfa3",
   "metadata": {},
   "source": [
    "# 写在前面\n",
    "\n",
    "+ NMT教程来自[https://tensorflow.google.cn/text/tutorials/transformer](https://tensorflow.google.cn/text/tutorials/transformer)<br/>\n",
    "+ 数据集来自教程[https://tensorflow.google.cn/text/tutorials/nmt_with_attention](https://tensorflow.google.cn/text/tutorials/nmt_with_attention)中的链接[http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip](http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip)。或者已经下载解压缩在该项目目录`spa-eng`中<br/>\n",
    "+ 任务：从Spanish翻译为English<br/>\n",
    "+ 运行：进入项目目录，然后直接`python local_runner.py`\n",
    "+ 环境：见`requirement.yaml`，需要tfx(1.13.0)可能旧版本会有不兼容，api不稳定。\n",
    "+ 项目目录介绍\n",
    "    + `custom`目录包含定义的预处理（教程来自[https://tensorflow.google.cn/text/guide/subwords_tokenizer](https://tensorflow.google.cn/text/guide/subwords_tokenizer)..等）和Transformer模型\n",
    "    + `data`目录包含pipeline需要的输入数据，下面的`创建pipeline数据`就是生成这个\n",
    "    + `models`目录包含pipeline需要的预处理和模型训练代码。\n",
    "        + `constants.py` 定义预处理和模型训练参数\n",
    "        + `model.py` 定义pipeline需要进行的模型训练步骤\n",
    "        + `preprocessing.py` 定义预处理步骤\n",
    "    + `pipeline`目录包含Pipeline的配置参数和整个pipeline定义\n",
    "        + `configs.py` 定义pipeline参数\n",
    "        + `pipeline.py` 定义pipeline的组件，以及模型验证的配置\n",
    "    + `spa-eng`目录包含原始的数据集，pipeline不需要\n",
    "    + `tfx_metadata`目录是运行pipeline后自动生成的元数据目录\n",
    "    + `tfx_pipeline_output`目录是运行pipeline后自动生成的组件输出\n",
    "    + `vocab`目录包含生成的词表\n",
    "    + `local_runner.py`用于运行pipeline的python文件,运行直接`python local_runner.py`\n",
    "    + `moduletest.ipynb`就是本文件\n",
    "    + `requirement.yaml`就是程序运行的环境(tfx:1.13.0)，由conda导出，环境中有个包`model-card-toolkit`有冲突，可以不用。\n",
    "+ 注意：\n",
    "    + 每次生成vocab大小都不一样，需要修改`models`目录下的`constants.py`中的词表大小。\n",
    "    + 这个pipeline是在本地运行的。\n",
    "    + pipeline运行多次后，`tf_pipelie_output`可能变得很大，它包含每次各个组件的结果。如果不需要，整个删除\n",
    "    + `tf_pipelie_output`运行结果可以结合各个组件对应的库（如tfdv、tft、tfma、TF-serving）导入结果，可视化结果，部署模型等。\n",
    "    + 运行前，最好修改一下模型参数，由于笔者个人电脑限制，模型大小调小。如果资源足够，可以`d_model`和`dff`翻倍，`num_layers`为8，`batch`调大\n",
    "    + 导出的模型签名（示例都在下面）：\n",
    "        + `serving_default`签名函数，需要原始输入**序列化**后的examples数据，是为了用于`Evaluator`组件评估（一般模型输出就是我们需要的，但是这里不是）。\n",
    "        + `transform_features`是预处理的签名函数，需要原始输入**序列化**后的examples数据。\n",
    "        + `translator`是用于翻译的签名函数，需要原始输入**序列化**后的examples数据。（当然也可以改为Tensor输入）\n",
    "        + `train_step`是用于继续训练的`train_step`的签名函数，需要输入原始输入的**Tensor**数据（比较方便）。一次输入一个batch的数据。当然也可以直接加载原始数据，然后用`transform_features`签名函数预处理（先batch再预处理），最后用没有任何签名的模型（也就是刚加载的模型：它的输入是经过预处理的数据）使用`fit`方法训练(要有`fit`方法需要用第二种导入)\n",
    "    + 该pipeline还可以扩展或优化，比如\n",
    "        + 添加Tuner组件，进行超参数调优\n",
    "        + 增加保存点，进行断点续训\n",
    "        + 将`translator`输入签名变为原始输入Tensor，就不用再序列化。\n",
    "        + 在运行pipeline前，正确定义`Schema`然后将其路径作为`create_pipeline`函数的参数`schema_path`，这样可以多个`ExampleValidator`数据验证组件，提前观测数据漂移，训练-服务偏斜，其他异常等。\n",
    "        + 添加kubeflow的config配置(需要能访问到整个项目文件，比如将这个文件放到云存储桶中或绑定一个持久卷声明，建议查看tfx的template示例)，运行后生成pipeline的压缩文件，然后可以上传到kubeflow的pipeline上运行。（需要能访问外网，因为`workflow`需要`gcr`的镜像，镜像很大）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42b3b69-c9dc-4442-9dad-41538d5a71a4",
   "metadata": {},
   "source": [
    "# 预处理测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f1a819-52f5-4e36-b5da-478405689a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 20:01:41.287848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 20:01:44.243019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:absl:Failed to import tensorflow serving protos. It can fail if the TF version doesn't match with the TF Serving version. We will try importing again with a workaround:module 'tensorflow.core.protobuf.error_codes_pb2' has no attribute '_CODE'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "import tensorflow_text as tf_text\n",
    "from tfx import v1 as tfx\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "import tempfile\n",
    "\n",
    "from custom.bertpreprocess import BertTokenizerModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ec3133b-d068-413f-92bf-cf9ac643389a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = [\n",
    "    {'context':b'Una vez hubo aqu\\xc3\\xad una iglesia.','target':b'There was a church here once.'},\n",
    "    {'context':b'\\xc2\\xbfCu\\xc3\\xa1l es tu nombre completo?','target':b\"What's your full name?\"},\n",
    "    {'context':b'No tendr\\xc3\\xa1s ning\\xc3\\xban problema m\\xc3\\xa1s.','target':b\"You'll have no more problems.\"},\n",
    "    {'context':b'Tom le mostr\\xc3\\xb3 a Mary la foto de John.','target':b\"Tom showed Mary John's picture.\"},\n",
    "    {'context':b'Pareces un polic\\xc3\\xada.','target':b'You look like a policeman.'},\n",
    "]\n",
    "\n",
    "raw_data_metadata = tft.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec({\n",
    "        'context': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
    "        'target': tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93a622fb-3fed-489a-a38a-33c25d641c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'Una vez hubo aqu\\xc3\\xad una iglesia.'</td>\n",
       "      <td>b'There was a church here once.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\xc2\\xbfCu\\xc3\\xa1l es tu nombre completo?'</td>\n",
       "      <td>b\"What's your full name?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'No tendr\\xc3\\xa1s ning\\xc3\\xban problema m\\x...</td>\n",
       "      <td>b\"You'll have no more problems.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Tom le mostr\\xc3\\xb3 a Mary la foto de John.'</td>\n",
       "      <td>b\"Tom showed Mary John's picture.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'Pareces un polic\\xc3\\xada.'</td>\n",
       "      <td>b'You look like a policeman.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0           b'Una vez hubo aqu\\xc3\\xad una iglesia.'   \n",
       "1      b'\\xc2\\xbfCu\\xc3\\xa1l es tu nombre completo?'   \n",
       "2  b'No tendr\\xc3\\xa1s ning\\xc3\\xban problema m\\x...   \n",
       "3    b'Tom le mostr\\xc3\\xb3 a Mary la foto de John.'   \n",
       "4                      b'Pareces un polic\\xc3\\xada.'   \n",
       "\n",
       "                               target  \n",
       "0    b'There was a church here once.'  \n",
       "1           b\"What's your full name?\"  \n",
       "2    b\"You'll have no more problems.\"  \n",
       "3  b\"Tom showed Mary John's picture.\"  \n",
       "4       b'You look like a policeman.'  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(raw_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b45059a-7874-4cea-a9ea-8adb2e130098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 0             b'Una vez hubo aqu\\xc3\\xad una iglesia.'\n",
       " 1        b'\\xc2\\xbfCu\\xc3\\xa1l es tu nombre completo?'\n",
       " 2    b'No tendr\\xc3\\xa1s ning\\xc3\\xban problema m\\x...\n",
       " 3      b'Tom le mostr\\xc3\\xb3 a Mary la foto de John.'\n",
       " 4                        b'Pareces un polic\\xc3\\xada.'\n",
       " Name: context, dtype: object,\n",
       " 'target': 0      b'There was a church here once.'\n",
       " 1             b\"What's your full name?\"\n",
       " 2      b\"You'll have no more problems.\"\n",
       " 3    b\"Tom showed Mary John's picture.\"\n",
       " 4         b'You look like a policeman.'\n",
       " Name: target, dtype: object}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d5f23c-78ef-42b0-8099-221c7e4ff37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_TOKENS=30\n",
    "def preprocessing_fn(inputs):\n",
    "    with tf.init_scope():\n",
    "        en_tokenizer=BertTokenizerModule('./vocab/en_vocab.txt')\n",
    "        spa_tokenizer=BertTokenizerModule('./vocab/spa_vocab.txt')\n",
    "    spa = spa_tokenizer.tokenize(tf_text.normalize_utf8(inputs['context'],'NFKD'))\n",
    "    spa, _ = tf_text.pad_model_inputs(spa,max_seq_length=MAX_TOKENS)\n",
    "    \n",
    "    en = en_tokenizer.tokenize(tf_text.normalize_utf8(inputs['target'],'NFKD'))\n",
    "    en, _ = tf_text.pad_model_inputs(en,max_seq_length=MAX_TOKENS+1)\n",
    "    en_inputs = en[:,:-1]\n",
    "    en_labels = en[:,1:]\n",
    "    \n",
    "    return {\n",
    "        'context_in':spa,\n",
    "        'target_in':en_inputs,\n",
    "        'target_out':en_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a8f4d8-2ab0-4ab9-9269-f8d1d6001584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(output_dir):\n",
    "    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "        transformed_dataset, transform_fn = (\n",
    "            (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)\n",
    "        )\n",
    "    transformed_data, transformed_metadata = transformed_dataset\n",
    "    \n",
    "    _ = (\n",
    "        transform_fn\n",
    "        | 'WriteTransformFn' >> tft_beam.WriteTransformFn(output_dir))\n",
    "    return transformed_data, transformed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d19d17-0c41-4737-95eb-071e9b08ce36",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "2023-07-12 16:05:27.948661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-12 16:05:28.017529: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:You are passing instance dicts and DatasetMetadata to TFT which will not provide optimal performance. Consider following the TFT guide to upgrade to the TFXIO format (Apache Arrow RecordBatch).\n",
      "WARNING:absl:You are outputting instance dicts from `TransformDataset` which will not provide optimal performance. Consider setting  `output_record_batches=True` to upgrade to the TFXIO format (Apache Arrow RecordBatch). Encoding functionality in this module works with both formats.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/home/xzy/anaconda3/envs/tfx/lib/python3.9/site-packages/ipykernel_launcher.py', '-f', '/home/xzy/.local/share/jupyter/runtime/kernel-556c4c67-5714-4385-b1d9-794589411043.json']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd1xlh5dp/tftransform_tmp/81b2cef6d77041b5a3d7d63b0399f8aa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd1xlh5dp/tftransform_tmp/81b2cef6d77041b5a3d7d63b0399f8aa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['/home/xzy/anaconda3/envs/tfx/lib/python3.9/site-packages/ipykernel_launcher.py', '-f', '/home/xzy/.local/share/jupyter/runtime/kernel-556c4c67-5714-4385-b1d9-794589411043.json']\n"
     ]
    }
   ],
   "source": [
    "output_dir = tempfile.mkdtemp()\n",
    "transformed_data, transformed_metadata=main(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b004bf1f-f713-4777-b0f6-93d01c4755ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_output = tft.TFTransformOutput(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc663d91-ea36-4a1e-9c68-1e2dbbb13f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    }
   ],
   "source": [
    "infer=tf_output.transform_features_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4985ef72-d493-4704-a9d2-5193b493d753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_in': <tf.Tensor: shape=(2, 30), dtype=int64, numpy=\n",
       " array([[   2,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    1,  128,  821,    1,   78, 1060,   15,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])>,\n",
       " 'target_in': <tf.Tensor: shape=(2, 30), dtype=int64, numpy=\n",
       " array([[  2,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  2,   1,  66,  26, 970, 108, 391,  11,   3,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]])>,\n",
       " 'target_out': <tf.Tensor: shape=(2, 30), dtype=int64, numpy=\n",
       " array([[  3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  1,  66,  26, 970, 108, 391,  11,   3,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]])>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer({'context':tf.constant(['',b'Una vez hubo aqu\\xc3\\xad una iglesia.']),\n",
    "      'target':tf.constant(['',b'There was a church here once.'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47c421-2953-4783-94c9-506a320533e6",
   "metadata": {},
   "source": [
    "# 创建pipeline数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc69b06-b6c2-4bfc-84b4-e70a8cc2601e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 21:08:26.017291: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 21:08:26.679469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text\n",
    "from custom.bertpreprocess import BertPreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37d4cb0-1e56-41fe-a929-97444b0227f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download the file\n",
    "import pathlib\n",
    "\n",
    "# path_to_zip = tf.keras.utils.get_file(\n",
    "#     'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "#     extract=True,cache_dir='.',cache_subdir='.')\n",
    "\n",
    "# path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n",
    "path_to_file = pathlib.Path('./spa-eng/spa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5a4391-4750-4423-a0c1-2e7092707db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path: pathlib.Path):\n",
    "    text = path.read_text(encoding='utf-8')\n",
    "    lines = text.splitlines()\n",
    "    pairs = [line.split('\\t')  for line in lines]\n",
    "    \n",
    "    en = np.array([en for en, spa in pairs])\n",
    "    spa = np.array([spa for en, spa in pairs])\n",
    "    return en, spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b84c2ca-2cbe-4806-9bab-13c8e73c85b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_raw, spa_raw = load_data(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1cadcb-4646-4278-81b5-d9b79908998a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 21:08:32.775343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-14 21:08:32.799577: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(spa_raw)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "is_train = np.random.uniform(size=(len(en_raw),)) < 0.8\n",
    "\n",
    "train_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((spa_raw[is_train], en_raw[is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))\n",
    "val_raw = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((spa_raw[~is_train], en_raw[~is_train]))\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfabbd-d04c-4245-b331-89393a070fd9",
   "metadata": {},
   "source": [
    "## 生成词表(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea8c10c3-3cd6-4711-ae20-7a29a5c3f56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4801, 3888)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#不同次运行，可能生成不同大小的词汇表\n",
    "#需要修改models目录下constants.py中的参数\n",
    "len(spa_vocab),len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db857de8-a994-4280-99c7-2cb8de6dec31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7ff4a9802ee0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ff4a9802ee0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ff4a9802ee0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ff4a9802ee0>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 21:08:35.375294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [95271]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-14 21:08:35.375514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [95271]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7ff576e47310> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ff576e47310>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ff576e47310> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7ff576e47310>: no matching AST found among candidates:\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 21:09:10.383556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [95271]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-14 21:09:10.383806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [95271]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.6 s, sys: 684 ms, total: 55.3 s\n",
      "Wall time: 53.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_vocab_size = 5000\n",
    "spa_vocab = BertPreprocess.generate_vocab(train_raw.map(lambda spa,en:spa),max_vocab_size)\n",
    "en_vocab = BertPreprocess.generate_vocab(train_raw.map(lambda spa,en:en),max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d7aeec-d278-43f5-9fe3-4b8b15946aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#写入文件\n",
    "BertPreprocess.write_vocab_file('./vocab/en_vocab.txt',en_vocab)\n",
    "BertPreprocess.write_vocab_file('./vocab/spa_vocab.txt',spa_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed292d2f-a3bd-4a02-bc62-1847e6e2f60f",
   "metadata": {},
   "source": [
    "## 生成pipeline的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c597323d-bc90-4348-a892-65245da40515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c0bb9a8-7833-4552-bde3-ba14c6460623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 20:02:00.316739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-13 20:02:00.506817: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = tf.data.Dataset.from_tensor_slices((spa_raw,en_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e2a27b-f1cf-43df-8ba6-b38f55d3d97f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_to_tfrecord(spa_line,en_line,f):\n",
    "    print(spa_line)\n",
    "    spa= spa_line.numpy()\n",
    "    print(spa)\n",
    "    en = en_line.numpy()\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'context':tf.train.Feature(bytes_list=tf.train.BytesList(value=[spa])),\n",
    "        'target':tf.train.Feature(bytes_list=tf.train.BytesList(value=[en])),\n",
    "    }))\n",
    "    f.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8388e069-e171-483e-a342-373166c2bdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 20:02:00.714819: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [118964]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "###写入数据集，请注释\n",
    "# with tf.io.TFRecordWriter('./data/data.tfrecord') as f:\n",
    "#     for spa_line,en_line in raw_dataset:\n",
    "#         spa= spa_line.numpy()\n",
    "#         en = en_line.numpy()\n",
    "#         example = tf.train.Example(features=tf.train.Features(feature={\n",
    "#             'context':tf.train.Feature(bytes_list=tf.train.BytesList(value=[spa])),\n",
    "#             'target':tf.train.Feature(bytes_list=tf.train.BytesList(value=[en])),\n",
    "#         }))\n",
    "#         f.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da247bb3-050e-4915-b90b-fa799d22c9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rel = tf.data.TFRecordDataset('./data/data.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fa1ad1-7297-4584-ba6d-ef5a455b00e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': <tf.Tensor: shape=(), dtype=string, numpy=b'Ve.'>, 'target': <tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>}\n",
      "{'context': <tf.Tensor: shape=(), dtype=string, numpy=b'Vete.'>, 'target': <tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>}\n",
      "{'context': <tf.Tensor: shape=(), dtype=string, numpy=b'Vaya.'>, 'target': <tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>}\n",
      "{'context': <tf.Tensor: shape=(), dtype=string, numpy=b'V\\xc3\\xa1yase.'>, 'target': <tf.Tensor: shape=(), dtype=string, numpy=b'Go.'>}\n",
      "{'context': <tf.Tensor: shape=(), dtype=string, numpy=b'Hola.'>, 'target': <tf.Tensor: shape=(), dtype=string, numpy=b'Hi.'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 20:02:34.959953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for ex in rel.take(5):\n",
    "    a=tf.io.parse_single_example(ex,{\n",
    "            'context':tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
    "            'target':tf.io.FixedLenFeature(shape=[],dtype=tf.string),\n",
    "        })\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d871a8a-9fa6-4dca-940f-3a92d606951a",
   "metadata": {},
   "source": [
    "# 模型测试（两种导入）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d91239-a2e5-4984-bbb9-68169c4e1907",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Failed to import tensorflow serving protos. It can fail if the TF version doesn't match with the TF Serving version. We will try importing again with a workaround:module 'tensorflow.core.protobuf.error_codes_pb2' has no attribute '_CODE'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow import keras\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "from models import constants\n",
    "from custom.TransformerModel import Transformer,TranslatorForTFX,CustomSchedule,masked_accuracy,masked_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb673f7-6d53-43a1-940c-eaa5b5d671ad",
   "metadata": {},
   "source": [
    "## 第一种导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "304b1309-c3b3-4b85-a672-5f4e329260b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 20:42:25.503655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-14 20:42:25.596098: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.saved_model.load('./tfx_pipeline_output/nmt3/Trainer/model/6/Format-Serving/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e79439-5baf-48ae-8fbd-4e9140585066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, examples) at 0x7EFD522E07F0>, 'transform_features': <ConcreteFunction signature_wrapper(*, examples) at 0x7EFD522C7D90>, 'translator': <ConcreteFunction signature_wrapper(*, examples) at 0x7EFD5236F6A0>, 'train_step': <ConcreteFunction signature_wrapper(*, context_tensor, target_tensor) at 0x7EFD521E2670>})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型所有签名\n",
    "model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4292ac-93e8-4d09-9667-b7001f7e22bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       "array([b'\\n]\\n.\\n\\x07context\\x12#\\n!\\n\\x1fUna vez hubo aqu\\xc3\\xad una iglesia.\\n+\\n\\x06target\\x12!\\n\\x1f\\n\\x1dThere was a church here once.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试数据\n",
    "spa = b'Una vez hubo aqu\\xc3\\xad una iglesia.'\n",
    "en = b'There was a church here once.'\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'context':tf.train.Feature(bytes_list=tf.train.BytesList(value=[spa])),\n",
    "        'target':tf.train.Feature(bytes_list=tf.train.BytesList(value=[en])),\n",
    "    })).SerializeToString()\n",
    "inputs = tf.constant([example])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edb30c-cfff-49a4-8035-4524d7fb5a88",
   "metadata": {},
   "source": [
    "## 预处理测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba83210-d9e7-4b5a-808d-bd672e5d8a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_out': <tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
       " array([[  1,  66,  26, 970, 108, 391,  11,   3,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0]])>,\n",
       " 'context_in': <tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
       " array([[   2,    1,  128,  821,    1,   78, 1060,   15,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]])>,\n",
       " 'target_in': <tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
       " array([[  2,   1,  66,  26, 970, 108, 391,  11,   3,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0]])>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.signatures['transform_features'](inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab3fad-7cb4-41bc-a8c6-ae6ab50d2fb8",
   "metadata": {},
   "source": [
    "## Serving_default测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e79f12-e2fe-42c9-83b8-db41c1203012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': <tf.Tensor: shape=(1, 20, 3868), dtype=float32, numpy=\n",
       " array([[[-13.698115 ,  15.020721 , -13.686973 , ..., -13.70266  ,\n",
       "          -13.703123 , -13.693153 ],\n",
       "         [-13.772773 ,   3.9995522, -13.760695 , ..., -13.778036 ,\n",
       "          -13.775291 , -13.768736 ],\n",
       "         [-11.426856 ,   1.8011227, -11.415457 , ..., -11.432271 ,\n",
       "          -11.428927 , -11.423204 ],\n",
       "         ...,\n",
       "         [-14.367573 ,  -1.4908874, -14.365833 , ..., -14.368966 ,\n",
       "          -14.367823 , -14.365198 ],\n",
       "         [-14.408494 ,  -1.4793062, -14.406815 , ..., -14.409847 ,\n",
       "          -14.408725 , -14.406109 ],\n",
       "         [-14.4906435,  -1.4972291, -14.488987 , ..., -14.492    ,\n",
       "          -14.490903 , -14.488233 ]]], dtype=float32)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.signatures['serving_default'](inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4234beeb-2ec5-46ce-a915-c6982b5d3708",
   "metadata": {},
   "source": [
    "## 翻译测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f51c08-2f8c-45f3-a1a1-50a626fcbb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': <tf.Tensor: shape=(1,), dtype=string, numpy=\n",
       " array([b'[UNK] you you may to you you you you may follow walked ?ter a itate you touch signrop be start meeting you you fool you even shouldes you you you you you mustap its to you you you you other ,ur the want to you you you you you you you you you you you you still you plenty private you you you make . you let willing pay tight you you not you you you you is re . tend successful you you you just you you you just you you you you you you you belt would way wfe youent want button isn once you you call be . youop you don you don he rich answer'],\n",
       "       dtype=object)>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa = b'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un m\\xc3\\xbasico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'context':tf.train.Feature(bytes_list=tf.train.BytesList(value=[spa])),\n",
    "    })).SerializeToString()\n",
    "inputs = tf.constant([example])\n",
    "model.signatures['translator'](inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5eca4d-5e6f-4f80-bc12-1bcd96b1bbd6",
   "metadata": {},
   "source": [
    "## 测试原始Tensor数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0d8458-f9c0-43e6-acb0-de71be09ee9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(118964,), dtype=string, numpy=\n",
       "array([b'Ve.', b'Vete.', b'Vaya.', ...,\n",
       "       b'Una huella de carbono es la cantidad de contaminaci\\xc3\\xb3n de di\\xc3\\xb3xido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque est\\xc3\\xa1n preocupados acerca del cambio clim\\xc3\\xa1tico.',\n",
       "       b'Como suele haber varias p\\xc3\\xa1ginas web sobre cualquier tema, normalmente s\\xc3\\xb3lo le doy al bot\\xc3\\xb3n de retroceso cuando entro en una p\\xc3\\xa1gina web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente p\\xc3\\xa1gina encontrada por Google y espero encontrar algo menos irritante.',\n",
       "       b'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un m\\xc3\\xbasico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将一维数据转为tensor类型，因为保存的模型的签名只接受Tensorflow专属类型输入\n",
    "spa_tensor = tf.convert_to_tensor(spa_raw)\n",
    "spa_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2af680-c0b1-4302-9d04-3c744a29acf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(118964,), dtype=string, numpy=\n",
       "array([b'Go.', b'Go.', b'Go.', ...,\n",
       "       b'A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.',\n",
       "       b'Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.',\n",
       "       b'If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tensor = tf.convert_to_tensor(en_raw)\n",
    "en_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a3cace-7fbc-4fce-8826-f9b7e638d1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'masked_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.67725986>,\n",
       " 'loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.6610923>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#需要指定关键字参数，否则报错，关键字为输入签名中的name设定\n",
    "model.signatures['train_step'](context_tensor=spa_tensor[:64],target_tensor=en_tensor[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cab098-b619-402b-9c76-89c8a96e4746",
   "metadata": {},
   "source": [
    "## 第二种导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d487243-e645-4eed-b25b-d0644bb25845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fd3bfe86a30> and <keras.engine.input_layer.InputLayer object at 0x7fd53d278280>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.legacy.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x7fd3bfe86a30> and <keras.engine.input_layer.InputLayer object at 0x7fd53d278280>).\n",
      "2023-07-14 20:44:10.156792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_1' with dtype float and shape [?,?]\n",
      "\t [[{{node inputs_1}}]]\n",
      "2023-07-14 20:44:10.156895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '115617' with dtype float and shape [2048,128]\n",
      "\t [[{{node 115617}}]]\n",
      "2023-07-14 20:44:10.237320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,?]\n",
      "\t [[{{node Placeholder_1}}]]\n",
      "2023-07-14 20:44:10.237433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'transformer/115968' with dtype float and shape [2048,128]\n",
      "\t [[{{node transformer/115968}}]]\n"
     ]
    }
   ],
   "source": [
    "#需要指定自定义的类（学习率调度）、函数（包括metrics，loss）\n",
    "model_load=tf.keras.models.load_model('./tfx_pipeline_output/nmt3/Trainer/model/6/Format-Serving/',\n",
    "custom_objects={'masked_accuracy':masked_accuracy,'masked_loss':masked_loss,'CustomSchedule':CustomSchedule})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc78f2c4-dea5-4dc8-93db-b5a82b6a376e",
   "metadata": {},
   "source": [
    "## train_step签名函数测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb4fb50-0853-4170-b5af-ddbd8d6f30f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = model_load.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1abcb7-e1da-4d14-ba96-fdab1ede9d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.6610311>,\n",
       " 'masked_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.6772633>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.signatures['train_step'](context_tensor=spa_tensor[:64],target_tensor=en_tensor[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c8de475-8ef0-41ac-9470-4715ccdee93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_train = model_load.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "864a50ca-91f7-49a5-b50e-75b2386cac31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(weights_train[0],model_load.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "946b095c-ddd2-47f8-a997-99149594eef5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#train_step后模型参数改变\n",
    "for i in range(len(weights)):\n",
    "    print(np.array_equal(weights[i],weights_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6971b72-68ae-483a-8f9b-c0e6c3fde1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.6604986>,\n",
       " 'masked_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.6773393>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.signatures['train_step'](context_tensor=spa_tensor[:64],target_tensor=en_tensor[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff399911-2cfa-45a3-8393-1ae8a459e756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights_train2 = model_load.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1a84021-ca07-4047-8675-aa743d802175",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(weights)):\n",
    "    print(np.array_equal(weights_train[i],weights_train2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a322e108-bf99-4195-a553-9880e65326c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(weights)):\n",
    "    print(np.array_equal(model_load.get_weights()[i],weights_train2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dbf594-9108-40ca-9209-a98bdd5e12e1",
   "metadata": {},
   "source": [
    "## 继续训练（通过原始文本数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cdf0d4b-853a-45b3-a1d5-30e909cfb520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_tensor_dataset = tf.data.Dataset.from_tensor_slices((spa_tensor,en_tensor)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f44712-088a-4aff-a50a-df1d32a64829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 20:45:27.488129: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2023-07-14 20:45:27.502371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype string and shape [118964]\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  tf.Tensor(9, shape=(), dtype=int64) ,  metrics:  {'loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.6589187>, 'masked_accuracy': <tf.Tensor: shape=(), dtype=float32, numpy=0.6777657>}}"
     ]
    }
   ],
   "source": [
    "for index, (context_b, target_b) in raw_tensor_dataset.take(10).enumerate():\n",
    "    metrics_dict=model_load.signatures['train_step'](context_tensor=context_b,target_tensor=target_b)\n",
    "    print('\\rStep: ',index,',  metrics: ',metrics_dict,end='',flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfxx2",
   "language": "python",
   "name": "tfxx2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
